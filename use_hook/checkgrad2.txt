module:  OutConv(
  (conv): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))
  (sigmoid): Sigmoid()
)
input:  (tensor([[[[6.2891e-06, 5.7941e-06, 7.1017e-06,  ..., 6.6248e-06,
           6.8823e-06, 7.5985e-06],
          [7.5702e-06, 5.2107e-06, 7.5018e-06,  ..., 7.4239e-06,
           5.4286e-06, 7.3525e-06],
          [7.5845e-06, 2.5121e-06, 4.8798e-06,  ..., 7.5750e-06,
           7.4313e-06, 7.4503e-06],
          ...,
          [7.4603e-06, 7.4607e-06, 1.7496e-06,  ..., 7.1319e-06,
           7.4191e-06, 7.6287e-06],
          [4.2991e-06, 3.1291e-06, 5.9779e-06,  ..., 2.1605e-06,
           1.2146e-07, 7.5284e-06],
          [1.4700e-06, 6.8017e-06, 2.1006e-06,  ..., 1.5308e-06,
           7.8983e-07, 3.1201e-06]]],


        [[[7.6036e-06, 7.3183e-06, 3.3173e-06,  ..., 7.4227e-06,
           5.6571e-06, 7.6008e-06],
          [7.3602e-06, 8.7821e-08, 7.8864e-08,  ..., 7.6264e-06,
           3.9884e-06, 7.6199e-06],
          [2.6248e-06, 6.7690e-06, 4.2585e-06,  ..., 0.0000e+00,
           7.6094e-06, 5.6892e-06],
          ...,
          [7.6290e-06, 2.8710e-06, 7.5622e-06,  ..., 7.6281e-06,
           2.2864e-06, 7.3326e-06],
          [7.2095e-06, 3.2748e-06, 1.7195e-07,  ..., 9.7834e-07,
           7.4753e-06, 7.0830e-06],
          [7.5632e-06, 2.5841e-06, 7.4049e-06,  ..., 6.5472e-06,
           3.2975e-06, 1.8418e-06]]]], device='cuda:0'),)
output:  (tensor([[[[4.3429e-05, 3.1716e-05, 1.1030e-04,  ..., 5.7941e-05,
           7.7915e-05, 1.8849e-03],
          [9.8401e-04, 2.4066e-05, 4.5634e-04,  ..., 2.8325e-04,
           2.6449e-05, 2.1025e-04],
          [1.2970e-03, 1.1375e-05, 2.1170e-05,  ..., 1.0703e-03,
           2.9381e-04, 3.2500e-04],
          ...,
          [3.4415e-04, 3.4495e-04, 9.8997e-06,  ..., 1.1700e-04,
           2.7685e-04, 7.8721e-02],
          [1.7478e-05, 1.2934e-05, 3.5246e-05,  ..., 1.0643e-05,
           7.7528e-06, 5.7625e-04],
          [9.4503e-06, 7.0327e-05, 1.0528e-05,  ..., 9.5444e-06,
           8.5104e-06, 1.2909e-05]]],


        [[[2.2527e-03, 1.8712e-04, 1.3499e-05,  ..., 2.8166e-04,
           2.9512e-05, 2.0365e-03],
          [2.1619e-04, 7.7182e-06, 7.7091e-06,  ..., 1.9234e-02,
           1.5987e-05, 6.1010e-03],
          [1.1631e-05, 6.7656e-05, 1.7268e-05,  ..., 7.6294e+06,
           2.9153e-03, 3.0001e-05],
          ...,
          [1.4350e-01, 1.2233e-05, 8.6657e-04,  ..., 4.3612e-02,
           1.0894e-05, 1.9610e-04],
          [1.3863e-04, 1.3367e-05, 7.8053e-06,  ..., 8.7516e-06,
           3.7774e-04, 1.0653e-04],
          [8.7918e-04, 1.1537e-05, 2.5925e-04,  ..., 5.3787e-05,
           1.3437e-05, 1.0057e-05]]]], device='cuda:0'),)
module:  Up(
  (up): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
  (conv): DoubleConv(
    (double_conv): Sequential(
      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
  )
)
input:  (tensor([[[[ 0.0000e+00,  1.0630e-05,  0.0000e+00,  ...,  1.2154e-05,
            1.2626e-05,  1.3945e-05],
          [ 1.3890e-05,  0.0000e+00,  1.3767e-05,  ...,  1.3624e-05,
            0.0000e+00,  1.3494e-05],
          [ 1.3918e-05,  4.6107e-06,  8.9548e-06,  ...,  0.0000e+00,
            0.0000e+00,  1.3672e-05],
          ...,
          [ 0.0000e+00,  1.3692e-05,  3.2111e-06,  ...,  0.0000e+00,
            0.0000e+00,  1.4000e-05],
          [ 0.0000e+00,  5.7420e-06,  0.0000e+00,  ...,  3.9647e-06,
            0.0000e+00,  1.3815e-05],
          [ 2.6967e-06,  1.2482e-05,  0.0000e+00,  ...,  0.0000e+00,
            0.0000e+00,  5.7250e-06]],

         [[ 4.4153e-06,  4.0674e-06,  0.0000e+00,  ...,  0.0000e+00,
            0.0000e+00,  5.3360e-06],
          [ 5.3151e-06,  3.6594e-06,  5.2680e-06,  ...,  0.0000e+00,
            0.0000e+00,  5.1634e-06],
          [ 5.3256e-06,  0.0000e+00,  0.0000e+00,  ...,  5.3177e-06,
            5.2183e-06,  5.2314e-06],
          ...,
          [ 0.0000e+00,  5.2393e-06,  0.0000e+00,  ...,  5.0065e-06,
            0.0000e+00,  5.3570e-06],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
            0.0000e+00,  5.2863e-06],
          [ 1.0319e-06,  0.0000e+00,  0.0000e+00,  ...,  1.0751e-06,
            0.0000e+00,  0.0000e+00]],

         [[ 0.0000e+00, -8.7911e-06,  0.0000e+00,  ...,  0.0000e+00,
            0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00, -1.1386e-05,  ...,  0.0000e+00,
            0.0000e+00, -1.1160e-05],
          [ 0.0000e+00,  0.0000e+00, -7.4060e-06,  ...,  0.0000e+00,
           -1.1279e-05,  0.0000e+00],
          ...,
          [ 0.0000e+00, -1.1324e-05, -2.6557e-06,  ..., -1.0821e-05,
           -1.1262e-05,  0.0000e+00],
          [ 0.0000e+00, -4.7489e-06,  0.0000e+00,  ...,  0.0000e+00,
            0.0000e+00,  0.0000e+00],
          [ 0.0000e+00, -1.0323e-05,  0.0000e+00,  ...,  0.0000e+00,
           -1.1985e-06,  0.0000e+00]],

         ...,

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
            0.0000e+00,  5.6366e-06],
          [ 0.0000e+00,  3.8655e-06,  5.5648e-06,  ...,  0.0000e+00,
            0.0000e+00,  5.4543e-06],
          [ 0.0000e+00,  1.8637e-06,  0.0000e+00,  ...,  5.6173e-06,
            0.0000e+00,  5.5261e-06],
          ...,
          [ 0.0000e+00,  5.5344e-06,  1.2979e-06,  ...,  0.0000e+00,
            0.0000e+00,  5.6587e-06],
          [ 0.0000e+00,  2.3210e-06,  4.4347e-06,  ...,  0.0000e+00,
            0.0000e+00,  5.5841e-06],
          [ 0.0000e+00,  5.0453e-06,  1.5584e-06,  ...,  0.0000e+00,
            0.0000e+00,  0.0000e+00]],

         [[ 0.0000e+00,  1.1498e-06,  1.4093e-06,  ...,  1.3147e-06,
            1.3657e-06,  1.5084e-06],
          [ 0.0000e+00,  0.0000e+00,  1.4892e-06,  ...,  0.0000e+00,
            1.0773e-06,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
            1.4751e-06,  0.0000e+00],
          ...,
          [ 1.4811e-06,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
            0.0000e+00,  0.0000e+00],
          [ 8.5329e-07,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
            0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
            1.5676e-07,  0.0000e+00]],

         [[-1.4050e-05,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
            0.0000e+00, -1.6980e-05],
          [ 0.0000e+00, -1.1645e-05,  0.0000e+00,  ..., -1.6589e-05,
            0.0000e+00, -1.6431e-05],
          [ 0.0000e+00, -5.6143e-06, -1.0904e-05,  ..., -1.6922e-05,
           -1.6606e-05,  0.0000e+00],
          ...,
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.5932e-05,
           -1.6581e-05, -1.7047e-05],
          [ 0.0000e+00, -6.9919e-06,  0.0000e+00,  ..., -4.8277e-06,
           -2.7130e-07, -1.6822e-05],
          [-3.2837e-06, -1.5199e-05, -4.6946e-06,  ..., -3.4210e-06,
           -1.7646e-06, -6.9711e-06]]],


        [[[ 1.3952e-05,  1.3425e-05,  0.0000e+00,  ...,  1.3624e-05,
            0.0000e+00,  1.3945e-05],
          [ 1.3507e-05,  0.0000e+00,  0.0000e+00,  ...,  1.3993e-05,
            7.3211e-06,  0.0000e+00],
          [ 4.8158e-06,  0.0000e+00,  7.8133e-06,  ...,  0.0000e+00,
            1.3965e-05,  0.0000e+00],
          ...,
          [ 1.4000e-05,  0.0000e+00,  0.0000e+00,  ...,  1.4000e-05,
            0.0000e+00,  1.3453e-05],
          [ 1.3227e-05,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
            0.0000e+00,  1.2995e-05],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
            0.0000e+00,  3.3803e-06]],

         [[ 0.0000e+00,  5.1372e-06,  2.3293e-06,  ...,  5.2131e-06,
            3.9733e-06,  5.3360e-06],
          [ 0.0000e+00,  6.1673e-08,  0.0000e+00,  ...,  5.3544e-06,
            2.8014e-06,  5.3491e-06],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
            0.0000e+00,  3.9942e-06],
          ...,
          [ 0.0000e+00,  2.0154e-06,  0.0000e+00,  ...,  5.3570e-06,
            0.0000e+00,  5.1477e-06],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
            0.0000e+00,  0.0000e+00],
          [ 5.3099e-06,  1.8140e-06,  5.2000e-06,  ...,  4.5958e-06,
            0.0000e+00,  0.0000e+00]],

         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.1267e-05,
            0.0000e+00,  0.0000e+00],
          [ 0.0000e+00, -1.3330e-07, -1.1969e-07,  ..., -1.1573e-05,
            0.0000e+00,  0.0000e+00],
          [-3.9828e-06,  0.0000e+00, -6.4619e-06,  ...,  0.0000e+00,
            0.0000e+00, -8.6328e-06],
          ...,
          [ 0.0000e+00, -4.3560e-06, -1.1476e-05,  ...,  0.0000e+00,
           -3.4712e-06,  0.0000e+00],
          [ 0.0000e+00, -4.9694e-06, -2.6094e-07,  ...,  0.0000e+00,
            0.0000e+00, -1.0747e-05],
          [ 0.0000e+00,  0.0000e+00, -1.1239e-05,  ...,  0.0000e+00,
            0.0000e+00,  0.0000e+00]],

         ...,

         [[ 0.0000e+00,  0.0000e+00,  2.4605e-06,  ...,  5.5067e-06,
            0.0000e+00,  5.6366e-06],
          [ 0.0000e+00,  0.0000e+00,  5.8499e-08,  ...,  5.6560e-06,
            0.0000e+00,  5.6504e-06],
          [ 0.0000e+00,  0.0000e+00,  3.1582e-06,  ...,  0.0000e+00,
            5.6449e-06,  4.2192e-06],
          ...,
          [ 5.6587e-06,  0.0000e+00,  5.6090e-06,  ...,  5.6587e-06,
            1.6965e-06,  5.4377e-06],
          [ 5.3465e-06,  2.4287e-06,  1.2753e-07,  ...,  7.2530e-07,
            5.5454e-06,  5.2525e-06],
          [ 0.0000e+00,  1.9162e-06,  5.4929e-06,  ...,  0.0000e+00,
            0.0000e+00,  1.3663e-06]],

         [[ 0.0000e+00,  1.4522e-06,  6.5845e-07,  ...,  0.0000e+00,
            1.1232e-06,  1.5084e-06],
          [ 0.0000e+00,  1.7434e-08,  0.0000e+00,  ...,  0.0000e+00,
            0.0000e+00,  0.0000e+00],
          [ 5.2092e-07,  1.3435e-06,  0.0000e+00,  ...,  0.0000e+00,
            1.5106e-06,  1.1291e-06],
          ...,
          [ 0.0000e+00,  5.6972e-07,  0.0000e+00,  ...,  0.0000e+00,
            0.0000e+00,  1.4552e-06],
          [ 1.4308e-06,  6.4995e-07,  0.0000e+00,  ...,  0.0000e+00,
            0.0000e+00,  1.4056e-06],
          [ 0.0000e+00,  5.1279e-07,  0.0000e+00,  ...,  0.0000e+00,
            6.5439e-07,  0.0000e+00]],

         [[ 0.0000e+00,  0.0000e+00, -7.4123e-06,  ...,  0.0000e+00,
            0.0000e+00, -1.6980e-05],
          [ 0.0000e+00, -1.9626e-07,  0.0000e+00,  ...,  0.0000e+00,
            0.0000e+00, -1.7022e-05],
          [ 0.0000e+00, -1.5124e-05,  0.0000e+00,  ...,  0.0000e+00,
            0.0000e+00, -1.2710e-05],
          ...,
          [ 0.0000e+00, -6.4134e-06,  0.0000e+00,  ..., -1.7047e-05,
            0.0000e+00, -1.6381e-05],
          [ 0.0000e+00, -7.3165e-06, -3.8419e-07,  ..., -2.1850e-06,
           -1.6706e-05,  0.0000e+00],
          [-1.6897e-05, -5.7725e-06,  0.0000e+00,  ..., -1.4625e-05,
           -7.3665e-06, -4.1161e-06]]]], device='cuda:0'),)
output:  (tensor([[[[ 1.1539e-05,  1.0630e-05,  1.3029e-05,  ...,  1.2154e-05,
            1.2626e-05,  1.3945e-05],
          [ 1.3890e-05,  9.5632e-06,  1.3767e-05,  ...,  1.3624e-05,
            9.9597e-06,  1.3494e-05],
          [ 1.3918e-05,  4.6107e-06,  8.9548e-06,  ...,  1.3897e-05,
            1.3637e-05,  1.3672e-05],
          ...,
          [ 1.3692e-05,  1.3692e-05,  3.2111e-06,  ...,  1.3084e-05,
            1.3617e-05,  1.4000e-05],
          [ 7.8885e-06,  5.7420e-06,  1.0971e-05,  ...,  3.9647e-06,
            2.2280e-07,  1.3815e-05],
          [ 2.6967e-06,  1.2482e-05,  3.8554e-06,  ...,  2.8095e-06,
            1.4492e-06,  5.7250e-06]],

         [[ 4.4153e-06,  4.0674e-06,  4.9855e-06,  ...,  4.6507e-06,
            4.8312e-06,  5.3360e-06],
          [ 5.3151e-06,  3.6594e-06,  5.2680e-06,  ...,  5.2131e-06,
            3.8111e-06,  5.1634e-06],
          [ 5.3256e-06,  1.7643e-06,  3.4266e-06,  ...,  5.3177e-06,
            5.2183e-06,  5.2314e-06],
          ...,
          [ 5.2393e-06,  5.2393e-06,  1.2287e-06,  ...,  5.0065e-06,
            5.2105e-06,  5.3570e-06],
          [ 3.0185e-06,  2.1972e-06,  4.1982e-06,  ...,  1.5171e-06,
            8.5256e-08,  5.2863e-06],
          [ 1.0319e-06,  4.7763e-06,  1.4753e-06,  ...,  1.0751e-06,
            5.5453e-07,  2.1907e-06]],

         [[-9.5430e-06, -8.7911e-06, -1.0775e-05,  ..., -1.0052e-05,
           -1.0442e-05, -1.1533e-05],
          [-1.1488e-05, -7.9091e-06, -1.1386e-05,  ..., -1.1267e-05,
           -8.2370e-06, -1.1160e-05],
          [-1.1510e-05, -3.8132e-06, -7.4060e-06,  ..., -1.1493e-05,
           -1.1279e-05, -1.1307e-05],
          ...,
          [-1.1324e-05, -1.1324e-05, -2.6557e-06,  ..., -1.0821e-05,
           -1.1262e-05, -1.1578e-05],
          [-6.5240e-06, -4.7489e-06, -9.0737e-06,  ..., -3.2790e-06,
           -1.8427e-07, -1.1426e-05],
          [-2.2303e-06, -1.0323e-05, -3.1885e-06,  ..., -2.3236e-06,
           -1.1985e-06, -4.7347e-06]],

         ...,

         [[ 4.6640e-06,  4.2965e-06,  5.2664e-06,  ...,  4.9127e-06,
            5.1033e-06,  5.6366e-06],
          [ 5.6145e-06,  3.8655e-06,  5.5648e-06,  ...,  5.5067e-06,
            4.0258e-06,  5.4543e-06],
          [ 5.6256e-06,  1.8637e-06,  3.6196e-06,  ...,  5.6173e-06,
            5.5123e-06,  5.5261e-06],
          ...,
          [ 5.5344e-06,  5.5344e-06,  1.2979e-06,  ...,  5.2885e-06,
            5.5040e-06,  5.6587e-06],
          [ 3.1886e-06,  2.3210e-06,  4.4347e-06,  ...,  1.6026e-06,
            9.0058e-08,  5.5841e-06],
          [ 1.0900e-06,  5.0453e-06,  1.5584e-06,  ...,  1.1356e-06,
            5.8577e-07,  2.3141e-06]],

         [[ 1.2481e-06,  1.1498e-06,  1.4093e-06,  ...,  1.3147e-06,
            1.3657e-06,  1.5084e-06],
          [ 1.5025e-06,  1.0344e-06,  1.4892e-06,  ...,  1.4737e-06,
            1.0773e-06,  1.4596e-06],
          [ 1.5055e-06,  4.9874e-07,  9.6864e-07,  ...,  1.5032e-06,
            1.4751e-06,  1.4788e-06],
          ...,
          [ 1.4811e-06,  1.4811e-06,  3.4734e-07,  ...,  1.4152e-06,
            1.4729e-06,  1.5143e-06],
          [ 8.5329e-07,  6.2111e-07,  1.1868e-06,  ...,  4.2886e-07,
            2.4100e-08,  1.4944e-06],
          [ 2.9170e-07,  1.3502e-06,  4.1703e-07,  ...,  3.0390e-07,
            1.5676e-07,  6.1926e-07]],

         [[-1.4050e-05, -1.2943e-05, -1.5865e-05,  ..., -1.4800e-05,
           -1.5374e-05, -1.6980e-05],
          [-1.6914e-05, -1.1645e-05, -1.6764e-05,  ..., -1.6589e-05,
           -1.2128e-05, -1.6431e-05],
          [-1.6947e-05, -5.6143e-06, -1.0904e-05,  ..., -1.6922e-05,
           -1.6606e-05, -1.6647e-05],
          ...,
          [-1.6672e-05, -1.6672e-05, -3.9101e-06,  ..., -1.5932e-05,
           -1.6581e-05, -1.7047e-05],
          [-9.6055e-06, -6.9919e-06, -1.3360e-05,  ..., -4.8277e-06,
           -2.7130e-07, -1.6822e-05],
          [-3.2837e-06, -1.5199e-05, -4.6946e-06,  ..., -3.4210e-06,
           -1.7646e-06, -6.9711e-06]]],


        [[[ 1.3952e-05,  1.3425e-05,  6.0872e-06,  ...,  1.3624e-05,
            1.0384e-05,  1.3945e-05],
          [ 1.3507e-05,  1.6117e-07,  1.4473e-07,  ...,  1.3993e-05,
            7.3211e-06,  1.3979e-05],
          [ 4.8158e-06,  1.2421e-05,  7.8133e-06,  ...,  0.0000e+00,
            1.3965e-05,  1.0438e-05],
          ...,
          [ 1.4000e-05,  5.2670e-06,  1.3877e-05,  ...,  1.4000e-05,
            4.1972e-06,  1.3453e-05],
          [ 1.3227e-05,  6.0086e-06,  3.1551e-07,  ...,  1.7944e-06,
            1.3719e-05,  1.2995e-05],
          [ 1.3877e-05,  4.7406e-06,  1.3589e-05,  ...,  1.2010e-05,
            6.0496e-06,  3.3803e-06]],

         [[ 5.3387e-06,  5.1372e-06,  2.3293e-06,  ...,  5.2131e-06,
            3.9733e-06,  5.3360e-06],
          [ 5.1686e-06,  6.1673e-08,  5.5379e-08,  ...,  5.3544e-06,
            2.8014e-06,  5.3491e-06],
          [ 1.8428e-06,  4.7527e-06,  2.9898e-06,  ...,  0.0000e+00,
            5.3439e-06,  3.9942e-06],
          ...,
          [ 5.3570e-06,  2.0154e-06,  5.3099e-06,  ...,  5.3570e-06,
            1.6060e-06,  5.1477e-06],
          [ 5.0614e-06,  2.2992e-06,  1.2073e-07,  ...,  6.8662e-07,
            5.2497e-06,  4.9725e-06],
          [ 5.3099e-06,  1.8140e-06,  5.2000e-06,  ...,  4.5958e-06,
            2.3149e-06,  1.2935e-06]],

         [[-1.1539e-05, -1.1103e-05, -5.0344e-06,  ..., -1.1267e-05,
           -8.5875e-06, -1.1533e-05],
          [-1.1171e-05, -1.3330e-07, -1.1969e-07,  ..., -1.1573e-05,
           -6.0548e-06, -1.1561e-05],
          [-3.9828e-06, -1.0272e-05, -6.4619e-06,  ...,  0.0000e+00,
           -1.1550e-05, -8.6328e-06],
          ...,
          [-1.1578e-05, -4.3560e-06, -1.1476e-05,  ..., -1.1578e-05,
           -3.4712e-06, -1.1126e-05],
          [-1.0939e-05, -4.9694e-06, -2.6094e-07,  ..., -1.4840e-06,
           -1.1346e-05, -1.0747e-05],
          [-1.1476e-05, -3.9206e-06, -1.1239e-05,  ..., -9.9331e-06,
           -5.0033e-06, -2.7956e-06]],

         ...,

         [[ 5.6394e-06,  5.4266e-06,  2.4605e-06,  ...,  5.5067e-06,
            4.1971e-06,  5.6366e-06],
          [ 5.4598e-06,  6.5147e-08,  5.8499e-08,  ...,  5.6560e-06,
            2.9592e-06,  5.6504e-06],
          [ 1.9466e-06,  5.0205e-06,  3.1582e-06,  ...,  0.0000e+00,
            5.6449e-06,  4.2192e-06],
          ...,
          [ 5.6587e-06,  2.1289e-06,  5.6090e-06,  ...,  5.6587e-06,
            1.6965e-06,  5.4377e-06],
          [ 5.3465e-06,  2.4287e-06,  1.2753e-07,  ...,  7.2530e-07,
            5.5454e-06,  5.2525e-06],
          [ 5.6090e-06,  1.9162e-06,  5.4929e-06,  ...,  4.8547e-06,
            2.4453e-06,  1.3663e-06]],

         [[ 1.5092e-06,  1.4522e-06,  6.5845e-07,  ...,  1.4737e-06,
            1.1232e-06,  1.5084e-06],
          [ 1.4611e-06,  1.7434e-08,  1.5655e-08,  ...,  1.5136e-06,
            7.9192e-07,  1.5121e-06],
          [ 5.2092e-07,  1.3435e-06,  8.4516e-07,  ...,  0.0000e+00,
            1.5106e-06,  1.1291e-06],
          ...,
          [ 1.5143e-06,  5.6972e-07,  1.5010e-06,  ...,  1.5143e-06,
            4.5400e-07,  1.4552e-06],
          [ 1.4308e-06,  6.4995e-07,  3.4129e-08,  ...,  1.9410e-07,
            1.4840e-06,  1.4056e-06],
          [ 1.5010e-06,  5.1279e-07,  1.4700e-06,  ...,  1.2992e-06,
            6.5439e-07,  3.6564e-07]],

         [[-1.6989e-05, -1.6348e-05, -7.4123e-06,  ..., -1.6589e-05,
           -1.2644e-05, -1.6980e-05],
          [-1.6448e-05, -1.9626e-07, -1.7623e-07,  ..., -1.7039e-05,
           -8.9147e-06, -1.7022e-05],
          [-5.8640e-06, -1.5124e-05, -9.5140e-06,  ...,  0.0000e+00,
           -1.7005e-05, -1.2710e-05],
          ...,
          [-1.7047e-05, -6.4134e-06, -1.6897e-05,  ..., -1.7047e-05,
           -5.1107e-06, -1.6381e-05],
          [-1.6106e-05, -7.3165e-06, -3.8419e-07,  ..., -2.1850e-06,
           -1.6706e-05, -1.5823e-05],
          [-1.6897e-05, -5.7725e-06, -1.6548e-05,  ..., -1.4625e-05,
           -7.3665e-06, -4.1161e-06]]]], device='cuda:0'),)
module:  OutConv(
  (conv): Conv2d(160, 1, kernel_size=(1, 1), stride=(1, 1))
  (sigmoid): Sigmoid()
)
input:  (tensor([[[[ 0.0000e+00,  0.0000e+00,  1.5250e-05,  ...,  0.0000e+00,
            0.0000e+00,  1.5183e-05],
          [ 1.3455e-05,  1.5132e-05,  0.0000e+00,  ...,  1.5259e-05,
            1.5259e-05,  0.0000e+00],
          [ 0.0000e+00,  1.5259e-05,  1.5259e-05,  ...,  1.0286e-05,
            1.5303e-05,  0.0000e+00],
          ...,
          [ 0.0000e+00,  1.1959e-05,  1.5242e-05,  ...,  0.0000e+00,
            0.0000e+00,  0.0000e+00],
          [ 1.5259e-05,  1.0156e-10,  0.0000e+00,  ...,  1.5258e-05,
            0.0000e+00,  1.5259e-05],
          [ 1.5258e-05,  1.5259e-05,  1.5259e-05,  ...,  1.5259e-05,
            1.5259e-05,  0.0000e+00]]],


        [[[ 0.0000e+00,  1.5259e-05,  0.0000e+00,  ...,  4.5288e-08,
            1.5259e-05,  1.5259e-05],
          [ 1.5258e-05,  5.8920e-06,  1.5255e-05,  ...,  0.0000e+00,
            3.7956e-10, -1.6339e-07],
          [ 1.5259e-05,  1.3395e-05,  1.3420e-05,  ...,  0.0000e+00,
            8.1195e-08,  9.0746e-06],
          ...,
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  8.3466e-10,
            1.5259e-05,  8.1801e-06],
          [ 1.5259e-05,  1.5259e-05, -1.1758e-06,  ...,  1.5258e-05,
            1.5259e-05,  1.5259e-05],
          [ 1.5227e-05,  1.4672e-09,  0.0000e+00,  ...,  0.0000e+00,
            1.5259e-05,  1.5258e-05]]]], device='cuda:0'),)
output:  (tensor([[[[ 1.5259e+07,  1.5259e+07,  1.5298e-02,  ...,  1.5259e+07,
            1.5259e+07,  7.4940e-03],
          [ 1.5592e-04,  8.9756e-04,  1.5259e+07,  ...,  6.4000e+00,
            1.2800e+02,  1.5259e+07],
          [ 1.5259e+07,  4.4138e+00,  4.8305e-01,  ...,  4.4525e-05,
            4.0761e-03,  1.5259e+07],
          ...,
          [ 1.5259e+07,  1.0354e-04,  2.2775e-02,  ...,  1.5259e+07,
            1.5259e+07,  1.5259e+07],
          [ 9.8462e+00,  1.1304e-05,  1.5259e+07,  ...,  1.6432e-01,
            1.5259e+07,  6.4000e+00],
          [ 1.9938e-01,  9.1429e+00,  9.2754e-01,  ...,  4.0000e+00,
            1.6000e+01,  1.5259e+07]]],


        [[[ 1.5259e+07,  1.5422e+00,  1.5259e+07,  ...,  7.4537e-06,
            1.2800e+02,  1.8286e+01],
          [ 2.2399e-02,  2.9317e-05,  1.5004e-01,  ...,  1.5259e+07,
            2.2617e-05, -8.3196e-07],
          [ 6.4000e+01,  6.5766e-05,  1.6471e-04,  ...,  1.5259e+07,
            2.5591e-05,  4.7662e-05],
          ...,
          [ 1.5259e+07,  1.5259e+07,  1.5259e+07,  ...,  4.9190e-05,
            1.2800e+02,  3.2973e-05],
          [ 1.2800e+02,  2.3273e+00, -1.0672e-05,  ...,  5.0393e-01,
            3.2408e-01,  1.6000e+01],
          [ 2.5987e-03,  3.0127e-06,  1.5259e+07,  ...,  1.5259e+07,
            6.4000e+01,  2.5068e-02]]]], device='cuda:0'),)
module:  CBLModule(
  (conv1): Sequential(
    (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
    (1): ReLU(inplace=True)
  )
  (conv2): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
  )
  (conv3): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
    (1): ReLU(inplace=True)
  )
  (conv4): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))
    (1): ReLU(inplace=True)
  )
  (conv5): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))
    (1): ReLU(inplace=True)
  )
  (conv_out): Sequential(
    (0): Conv2d(320, 160, kernel_size=(1, 1), stride=(1, 1))
    (1): ReLU(inplace=True)
  )
  (drop): Dropout(p=0.2, inplace=False)
)
input:  (tensor([[[[0., 0., nan,  ..., 0., 0., 0.],
          [nan, 0., nan,  ..., 0., nan, 0.],
          [nan, nan, 0.,  ..., nan, 0., nan],
          ...,
          [0., nan, 0.,  ..., 0., nan, 0.],
          [nan, nan, 0.,  ..., nan, 0., nan],
          [0., 0., nan,  ..., 0., 0., 0.]],

         [[0., nan, nan,  ..., nan, 0., 0.],
          [nan, 0., 0.,  ..., 0., nan, nan],
          [nan, 0., 0.,  ..., nan, 0., nan],
          ...,
          [nan, 0., 0.,  ..., 0., 0., nan],
          [0., nan, 0.,  ..., nan, 0., nan],
          [nan, 0., nan,  ..., nan, nan, nan]],

         [[0., 0., 0.,  ..., 0., nan, nan],
          [0., nan, nan,  ..., nan, nan, 0.],
          [0., 0., nan,  ..., 0., nan, 0.],
          ...,
          [nan, 0., nan,  ..., 0., 0., nan],
          [nan, nan, nan,  ..., nan, 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         ...,

         [[0., nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[0., nan, nan,  ..., nan, 0., nan],
          [nan, nan, nan,  ..., 0., nan, 0.],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, 0., 0.,  ..., 0., 0., nan],
          [nan, nan, nan,  ..., nan, 0., nan]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., nan,  ..., nan, nan, 0.],
          [0., 0., nan,  ..., 0., 0., 0.],
          ...,
          [0., nan, 0.,  ..., 0., nan, nan],
          [0., 0., nan,  ..., 0., 0., nan],
          [0., 0., nan,  ..., 0., 0., nan]]],


        [[[0., 0., nan,  ..., nan, 0., 0.],
          [0., nan, nan,  ..., nan, nan, nan],
          [0., nan, nan,  ..., nan, nan, nan],
          ...,
          [0., nan, 0.,  ..., nan, nan, 0.],
          [nan, nan, nan,  ..., nan, 0., nan],
          [nan, nan, 0.,  ..., nan, 0., 0.]],

         [[0., nan, nan,  ..., 0., nan, nan],
          [nan, nan, nan,  ..., 0., 0., 0.],
          [nan, 0., 0.,  ..., 0., 0., 0.],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, 0.,  ..., 0., nan, nan],
          [nan, nan, 0.,  ..., nan, nan, 0.]],

         [[0., 0., 0.,  ..., 0., nan, 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., nan, 0.],
          ...,
          [nan, nan, 0.,  ..., 0., nan, 0.],
          [0., nan, 0.,  ..., nan, 0., 0.],
          [0., 0., nan,  ..., 0., 0., 0.]],

         ...,

         [[nan, nan, 0.,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, 0.],
          [nan, nan, nan,  ..., 0., nan, 0.],
          ...,
          [nan, 0., 0.,  ..., nan, 0., nan],
          [0., 0., 0.,  ..., 0., 0., nan],
          [0., nan, nan,  ..., 0., nan, nan]],

         [[0., 0., 0.,  ..., 0., nan, 0.],
          [0., 0., 0.,  ..., nan, 0., 0.],
          [0., nan, 0.,  ..., nan, nan, 0.],
          ...,
          [0., 0., 0.,  ..., nan, nan, 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [nan, 0., 0.,  ..., 0., 0., 0.]]]], device='cuda:0'),)
output:  (tensor([[[[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         ...,

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]]],


        [[[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         ...,

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0'),)
module:  Up(
  (up): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))
  (conv): DoubleConv(
    (double_conv): Sequential(
      (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
  )
)
input:  (tensor([[[[0., nan, nan,  ..., nan, 0., 0.],
          [0., 0., nan,  ..., 0., 0., 0.],
          [0., 0., nan,  ..., 0., 0., 0.],
          ...,
          [nan, 0., 0.,  ..., 0., 0., 0.],
          [nan, nan, 0.,  ..., nan, nan, 0.],
          [nan, 0., 0.,  ..., 0., nan, 0.]],

         [[0., nan, nan,  ..., 0., nan, nan],
          [nan, 0., 0.,  ..., 0., nan, 0.],
          [0., nan, nan,  ..., nan, nan, 0.],
          ...,
          [0., 0., nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [0., 0., nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, 0., 0.,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, 0.,  ..., nan, nan, nan],
          [nan, 0., 0.,  ..., nan, 0., nan],
          [nan, 0., nan,  ..., nan, nan, nan]],

         ...,

         [[0., nan, 0.,  ..., 0., 0., 0.],
          [nan, 0., 0.,  ..., 0., 0., 0.],
          [0., nan, nan,  ..., 0., 0., 0.],
          ...,
          [nan, 0., nan,  ..., 0., 0., 0.],
          [nan, 0., 0.,  ..., nan, 0., nan],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [nan, 0., nan,  ..., 0., nan, nan],
          [0., 0., 0.,  ..., 0., nan, 0.],
          ...,
          [nan, 0., 0.,  ..., 0., nan, nan],
          [nan, nan, 0.,  ..., nan, 0., nan],
          [0., 0., nan,  ..., 0., nan, 0.]],

         [[0., 0., 0.,  ..., nan, 0., nan],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., nan, nan,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., nan, 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]]],


        [[[0., 0., 0.,  ..., 0., 0., nan],
          [nan, 0., nan,  ..., nan, nan, 0.],
          [0., 0., 0.,  ..., nan, nan, 0.],
          ...,
          [nan, nan, nan,  ..., nan, 0., 0.],
          [nan, 0., nan,  ..., nan, 0., 0.],
          [nan, 0., nan,  ..., 0., 0., 0.]],

         [[0., nan, nan,  ..., nan, nan, nan],
          [0., 0., 0.,  ..., nan, nan, 0.],
          [nan, 0., nan,  ..., 0., nan, nan],
          ...,
          [nan, nan, nan,  ..., 0., 0., nan],
          [nan, nan, 0.,  ..., nan, nan, nan],
          [nan, nan, 0.,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., 0., 0., nan],
          [0., nan, nan,  ..., 0., 0., nan],
          [nan, nan, 0.,  ..., 0., 0., 0.],
          ...,
          [nan, nan, nan,  ..., 0., nan, nan],
          [nan, nan, 0.,  ..., 0., 0., nan],
          [nan, 0., 0.,  ..., nan, nan, nan]],

         ...,

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., nan, 0.,  ..., 0., nan, 0.],
          [0., nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, 0., 0.],
          [nan, nan, nan,  ..., nan, nan, 0.],
          [nan, 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., nan],
          [nan, nan, nan,  ..., 0., 0., 0.],
          [nan, 0., 0.,  ..., 0., nan, 0.],
          ...,
          [nan, nan, nan,  ..., 0., nan, nan],
          [nan, nan, 0.,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., nan],
          [0., 0., 0.,  ..., 0., 0., nan],
          [0., 0., 0.,  ..., nan, 0., nan],
          ...,
          [nan, 0., 0.,  ..., nan, nan, nan],
          [0., 0., nan,  ..., nan, nan, 0.],
          [nan, 0., nan,  ..., 0., 0., 0.]]]], device='cuda:0'),)
output:  (tensor([[[[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         ...,

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]]],


        [[[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         ...,

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0'),)
module:  OutConv(
  (conv): Conv2d(320, 1, kernel_size=(1, 1), stride=(1, 1))
  (sigmoid): Sigmoid()
)
input:  (tensor([[[[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]]],


        [[[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0'),)
output:  (tensor([[[[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]]],


        [[[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0'),)
module:  CBLModule(
  (conv1): Sequential(
    (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
    (1): ReLU(inplace=True)
  )
  (conv2): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
  )
  (conv3): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
    (1): ReLU(inplace=True)
  )
  (conv4): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))
    (1): ReLU(inplace=True)
  )
  (conv5): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))
    (1): ReLU(inplace=True)
  )
  (conv_out): Sequential(
    (0): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))
    (1): ReLU(inplace=True)
  )
  (drop): Dropout(p=0.2, inplace=False)
)
input:  (tensor([[[[0., 0., 0.,  ..., nan, 0., 0.],
          [nan, nan, 0.,  ..., nan, 0., 0.],
          [0., 0., 0.,  ..., nan, 0., 0.],
          ...,
          [0., nan, 0.,  ..., 0., 0., 0.],
          [nan, nan, nan,  ..., 0., 0., 0.],
          [nan, nan, 0.,  ..., nan, 0., 0.]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., 0., nan, nan],
          [nan, nan, nan,  ..., nan, 0., nan],
          [nan, 0., nan,  ..., nan, nan, 0.],
          ...,
          [0., nan, 0.,  ..., 0., nan, 0.],
          [nan, 0., 0.,  ..., nan, 0., 0.],
          [nan, 0., nan,  ..., 0., nan, 0.]],

         ...,

         [[0., 0., nan,  ..., 0., 0., 0.],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, 0., nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, 0.],
          [0., nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, 0., nan]],

         [[0., 0., 0.,  ..., nan, 0., nan],
          [0., 0., 0.,  ..., nan, 0., nan],
          [0., 0., 0.,  ..., nan, 0., nan],
          ...,
          [0., 0., 0.,  ..., nan, 0., 0.],
          [0., 0., 0.,  ..., nan, 0., nan],
          [nan, nan, 0.,  ..., nan, 0., 0.]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, 0., nan,  ..., 0., 0., nan],
          [nan, 0., 0.,  ..., nan, nan, nan],
          [nan, 0., 0.,  ..., 0., 0., nan]]],


        [[[nan, 0., nan,  ..., 0., 0., 0.],
          [nan, nan, 0.,  ..., 0., 0., nan],
          [0., 0., 0.,  ..., 0., 0., nan],
          ...,
          [0., nan, nan,  ..., 0., nan, nan],
          [nan, nan, 0.,  ..., nan, 0., nan],
          [nan, 0., 0.,  ..., 0., 0., 0.]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., 0., nan, nan],
          ...,
          [0., nan, nan,  ..., nan, nan, 0.],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, 0.,  ..., nan, nan, 0.],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, 0., 0.],
          ...,
          [nan, nan, nan,  ..., nan, 0., nan],
          [0., 0., 0.,  ..., 0., 0., nan],
          [nan, 0., 0.,  ..., 0., 0., 0.]],

         ...,

         [[nan, 0., 0.,  ..., 0., 0., nan],
          [0., 0., 0.,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, 0.],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., 0., nan, nan],
          [nan, nan, nan,  ..., 0., 0., nan]],

         [[0., 0., 0.,  ..., 0., 0., nan],
          [nan, 0., nan,  ..., nan, nan, 0.],
          [0., 0., nan,  ..., nan, nan, 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., nan, 0.,  ..., 0., 0., nan],
          [nan, 0., nan,  ..., 0., 0., 0.]],

         [[nan, 0., nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., 0., 0., 0.],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, 0.,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0'),)
output:  (tensor([[[[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         ...,

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]]],


        [[[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         ...,

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0'),)
module:  Up(
  (up): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))
  (conv): DoubleConv(
    (double_conv): Sequential(
      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
  )
)
input:  (tensor([[[[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, 0.,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., 0., nan, 0.],
          ...,
          [0., nan, nan,  ..., nan, nan, 0.],
          [0., nan, nan,  ..., nan, nan, 0.],
          [nan, nan, 0.,  ..., nan, nan, nan]],

         [[0., nan, 0.,  ..., nan, nan, nan],
          [0., 0., 0.,  ..., 0., nan, 0.],
          [nan, 0., nan,  ..., nan, 0., nan],
          ...,
          [0., 0., 0.,  ..., 0., nan, nan],
          [0., nan, 0.,  ..., 0., 0., 0.],
          [nan, nan, 0.,  ..., 0., nan, 0.]],

         [[0., nan, nan,  ..., nan, nan, 0.],
          [nan, 0., nan,  ..., nan, nan, nan],
          [nan, 0., 0.,  ..., nan, nan, 0.],
          ...,
          [0., nan, nan,  ..., nan, nan, 0.],
          [0., nan, 0.,  ..., 0., 0., 0.],
          [0., nan, nan,  ..., nan, nan, nan]],

         ...,

         [[nan, nan, nan,  ..., nan, nan, 0.],
          [nan, 0., 0.,  ..., 0., nan, nan],
          [nan, nan, 0.,  ..., 0., nan, nan],
          ...,
          [0., nan, 0.,  ..., nan, nan, nan],
          [nan, 0., 0.,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., 0., nan, nan]],

         [[nan, 0., 0.,  ..., 0., 0., 0.],
          [nan, nan, nan,  ..., 0., 0., nan],
          [nan, 0., nan,  ..., nan, 0., 0.],
          ...,
          [nan, 0., nan,  ..., nan, nan, 0.],
          [nan, 0., 0.,  ..., 0., 0., 0.],
          [nan, nan, nan,  ..., nan, nan, 0.]],

         [[nan, 0., nan,  ..., nan, nan, nan],
          [0., 0., 0.,  ..., nan, nan, nan],
          [0., 0., nan,  ..., 0., nan, 0.],
          ...,
          [0., nan, nan,  ..., 0., 0., nan],
          [nan, nan, 0.,  ..., 0., nan, nan],
          [0., nan, nan,  ..., nan, nan, 0.]]],


        [[[nan, nan, nan,  ..., nan, nan, nan],
          [0., 0., 0.,  ..., nan, nan, 0.],
          [0., 0., nan,  ..., 0., nan, 0.],
          ...,
          [0., nan, 0.,  ..., nan, 0., nan],
          [0., nan, 0.,  ..., nan, 0., 0.],
          [nan, nan, nan,  ..., nan, 0., nan]],

         [[0., nan, 0.,  ..., 0., 0., nan],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [nan, nan, 0.,  ..., nan, nan, 0.],
          ...,
          [0., nan, 0.,  ..., 0., 0., nan],
          [0., nan, 0.,  ..., 0., 0., nan],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., nan, 0.,  ..., nan, 0., 0.],
          [nan, 0., nan,  ..., nan, 0., 0.],
          [nan, 0., nan,  ..., nan, 0., 0.],
          ...,
          [nan, nan, nan,  ..., nan, 0., 0.],
          [nan, 0., 0.,  ..., nan, 0., 0.],
          [nan, nan, 0.,  ..., nan, nan, nan]],

         ...,

         [[nan, nan, nan,  ..., nan, nan, 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [nan, nan, 0.,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., 0., 0., 0.],
          [nan, 0., nan,  ..., nan, nan, 0.],
          [nan, 0., 0.,  ..., 0., 0., nan]],

         [[nan, 0., nan,  ..., nan, nan, 0.],
          [0., nan, 0.,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., 0., 0., nan],
          ...,
          [nan, 0., nan,  ..., nan, nan, nan],
          [nan, 0., nan,  ..., 0., 0., nan],
          [nan, 0., nan,  ..., nan, 0., nan]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., nan, nan,  ..., 0., 0., 0.],
          [nan, 0., nan,  ..., 0., 0., 0.],
          ...,
          [0., 0., nan,  ..., 0., nan, 0.],
          [0., 0., 0.,  ..., 0., nan, nan],
          [0., 0., 0.,  ..., 0., nan, 0.]]]], device='cuda:0'),)
output:  (tensor([[[[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         ...,

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]]],


        [[[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         ...,

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0'),)
module:  OutConv(
  (conv): Conv2d(320, 1, kernel_size=(1, 1), stride=(1, 1))
  (sigmoid): Sigmoid()
)
input:  (tensor([[[[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]]],


        [[[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0'),)
output:  (tensor([[[[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]]],


        [[[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0'),)
module:  CBLModule(
  (conv1): Sequential(
    (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (1): ReLU(inplace=True)
  )
  (conv2): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
  )
  (conv3): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
    (1): ReLU(inplace=True)
  )
  (conv4): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))
    (1): ReLU(inplace=True)
  )
  (conv5): Sequential(
    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))
    (1): ReLU(inplace=True)
  )
  (conv_out): Sequential(
    (0): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))
    (1): ReLU(inplace=True)
  )
  (drop): Dropout(p=0.2, inplace=False)
)
input:  (tensor([[[[0., 0., 0.,  ..., nan, 0., 0.],
          [nan, 0., 0.,  ..., 0., 0., 0.],
          [0., 0., nan,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., nan, nan, nan],
          [nan, 0., nan,  ..., 0., 0., 0.],
          [nan, 0., 0.,  ..., 0., nan, 0.],
          ...,
          [0., nan, nan,  ..., 0., 0., 0.],
          [nan, nan, nan,  ..., nan, 0., nan],
          [0., 0., 0.,  ..., 0., nan, 0.]],

         [[nan, 0., 0.,  ..., 0., 0., 0.],
          [nan, nan, nan,  ..., nan, 0., 0.],
          [nan, nan, 0.,  ..., 0., 0., 0.],
          ...,
          [nan, 0., 0.,  ..., 0., 0., 0.],
          [0., 0., nan,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         ...,

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, 0.,  ..., nan, nan, nan],
          [0., nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[0., 0., nan,  ..., nan, 0., nan],
          [0., 0., 0.,  ..., nan, nan, 0.],
          [nan, 0., 0.,  ..., 0., nan, 0.],
          ...,
          [0., 0., nan,  ..., 0., 0., 0.],
          [0., nan, nan,  ..., nan, nan, 0.],
          [0., 0., nan,  ..., 0., nan, nan]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., nan, 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [nan, 0., 0.,  ..., 0., 0., 0.],
          [0., 0., nan,  ..., nan, nan, nan],
          [0., 0., 0.,  ..., 0., 0., nan]]],


        [[[0., 0., nan,  ..., 0., 0., 0.],
          [0., nan, nan,  ..., 0., nan, 0.],
          [nan, 0., nan,  ..., 0., 0., 0.],
          ...,
          [0., nan, 0.,  ..., nan, 0., 0.],
          [0., 0., nan,  ..., 0., 0., 0.],
          [0., 0., nan,  ..., 0., 0., nan]],

         [[0., 0., 0.,  ..., nan, nan, nan],
          [0., 0., 0.,  ..., nan, nan, nan],
          [0., 0., 0.,  ..., nan, 0., 0.],
          ...,
          [0., nan, nan,  ..., 0., 0., 0.],
          [0., nan, 0.,  ..., nan, nan, 0.],
          [0., nan, 0.,  ..., 0., 0., 0.]],

         [[0., 0., nan,  ..., nan, 0., 0.],
          [0., nan, nan,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., nan,  ..., 0., 0., nan],
          [0., 0., 0.,  ..., 0., nan, 0.],
          [0., 0., nan,  ..., 0., 0., 0.]],

         ...,

         [[0., nan, 0.,  ..., nan, nan, nan],
          [nan, nan, 0.,  ..., 0., nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, 0., nan],
          [0., nan, 0.,  ..., nan, 0., nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[0., 0., nan,  ..., nan, 0., nan],
          [nan, 0., nan,  ..., nan, nan, 0.],
          [0., 0., 0.,  ..., nan, 0., nan],
          ...,
          [0., nan, 0.,  ..., 0., 0., nan],
          [nan, nan, nan,  ..., nan, 0., nan],
          [nan, 0., 0.,  ..., nan, 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [nan, nan, 0.,  ..., 0., 0., 0.],
          [nan, 0., 0.,  ..., 0., 0., 0.],
          ...,
          [nan, 0., 0.,  ..., 0., 0., 0.],
          [nan, 0., nan,  ..., 0., 0., nan],
          [nan, 0., nan,  ..., 0., 0., nan]]]], device='cuda:0'),)
output:  (tensor([[[[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         ...,

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]]],


        [[[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         ...,

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0'),)
module:  Up(
  (up): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))
  (conv): DoubleConv(
    (double_conv): Sequential(
      (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
  )
)
input:  (tensor([[[[0., nan, nan,  ..., 0., nan, 0.],
          [0., nan, nan,  ..., 0., 0., nan],
          [nan, nan, nan,  ..., 0., 0., 0.],
          ...,
          [nan, nan, nan,  ..., 0., 0., 0.],
          [nan, 0., nan,  ..., 0., 0., 0.],
          [nan, nan, nan,  ..., 0., nan, 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., nan, 0.],
          [0., 0., nan,  ..., nan, nan, nan],
          ...,
          [0., nan, nan,  ..., nan, nan, nan],
          [0., 0., 0.,  ..., 0., nan, nan],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[nan, 0., nan,  ..., nan, 0., 0.],
          [nan, 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., nan, 0., nan],
          ...,
          [nan, nan, 0.,  ..., 0., nan, 0.],
          [nan, nan, 0.,  ..., 0., 0., 0.],
          [nan, 0., 0.,  ..., nan, 0., 0.]],

         ...,

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [nan, nan, 0.,  ..., 0., 0., 0.],
          [0., nan, 0.,  ..., nan, 0., 0.],
          ...,
          [0., nan, nan,  ..., 0., 0., 0.],
          [0., nan, 0.,  ..., nan, 0., 0.],
          [nan, 0., 0.,  ..., nan, 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., nan, 0.,  ..., nan, 0., nan],
          [nan, 0., 0.,  ..., 0., 0., 0.],
          ...,
          [nan, nan, nan,  ..., nan, nan, 0.],
          [nan, 0., 0.,  ..., nan, 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[nan, nan, nan,  ..., 0., 0., 0.],
          [nan, nan, 0.,  ..., nan, nan, 0.],
          [nan, nan, 0.,  ..., nan, 0., 0.],
          ...,
          [nan, nan, 0.,  ..., 0., 0., 0.],
          [nan, 0., 0.,  ..., 0., 0., 0.],
          [nan, 0., 0.,  ..., nan, nan, nan]]],


        [[[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., nan, 0.],
          [nan, nan, 0.,  ..., 0., nan, nan],
          ...,
          [nan, 0., nan,  ..., nan, nan, nan],
          [nan, 0., nan,  ..., 0., nan, 0.],
          [nan, nan, nan,  ..., 0., nan, 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., nan,  ..., 0., 0., nan],
          [0., 0., nan,  ..., nan, 0., nan],
          ...,
          [0., nan, nan,  ..., 0., nan, nan],
          [0., 0., 0.,  ..., 0., 0., nan],
          [0., 0., nan,  ..., 0., 0., nan]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., nan,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., nan, 0.],
          ...,
          [0., nan, nan,  ..., 0., nan, 0.],
          [nan, 0., 0.,  ..., nan, 0., 0.],
          [nan, nan, 0.,  ..., 0., 0., 0.]],

         ...,

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [nan, nan, 0.,  ..., 0., 0., 0.],
          [nan, nan, 0.,  ..., nan, 0., 0.],
          ...,
          [0., nan, nan,  ..., nan, 0., 0.],
          [0., nan, 0.,  ..., 0., nan, 0.],
          [nan, nan, 0.,  ..., 0., nan, 0.]],

         [[0., 0., 0.,  ..., 0., 0., nan],
          [0., nan, nan,  ..., nan, 0., nan],
          [0., nan, 0.,  ..., nan, 0., nan],
          ...,
          [0., nan, nan,  ..., 0., nan, nan],
          [nan, nan, 0.,  ..., nan, 0., 0.],
          [0., 0., 0.,  ..., nan, nan, 0.]],

         [[nan, 0., 0.,  ..., 0., 0., 0.],
          [nan, 0., 0.,  ..., nan, 0., nan],
          [0., nan, 0.,  ..., 0., nan, nan],
          ...,
          [nan, nan, 0.,  ..., nan, nan, nan],
          [nan, 0., 0.,  ..., 0., 0., nan],
          [nan, nan, 0.,  ..., nan, 0., 0.]]]], device='cuda:0'),)
output:  (tensor([[[[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         ...,

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]]],


        [[[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         ...,

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0'),)
module:  Down(
  (maxpool_conv): Sequential(
    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (1): DoubleConv(
      (double_conv): Sequential(
        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU(inplace=True)
      )
    )
  )
)
input:  (tensor([[[[0., nan, 0.,  ..., 0., 0., 0.],
          [0., 0., nan,  ..., 0., nan, nan],
          [0., 0., 0.,  ..., nan, nan, 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., nan, nan, nan],
          [0., 0., nan,  ..., nan, nan, 0.]],

         [[0., 0., 0.,  ..., nan, nan, 0.],
          [nan, 0., 0.,  ..., nan, nan, 0.],
          [0., 0., nan,  ..., 0., 0., 0.],
          ...,
          [nan, 0., nan,  ..., 0., 0., 0.],
          [0., 0., nan,  ..., nan, 0., 0.],
          [0., 0., 0.,  ..., nan, 0., 0.]],

         [[nan, 0., 0.,  ..., nan, 0., 0.],
          [nan, nan, 0.,  ..., 0., nan, nan],
          [nan, nan, 0.,  ..., nan, nan, nan],
          ...,
          [nan, nan, 0.,  ..., nan, nan, nan],
          [nan, 0., 0.,  ..., 0., 0., 0.],
          [nan, nan, nan,  ..., 0., nan, nan]],

         ...,

         [[0., nan, nan,  ..., 0., nan, nan],
          [0., 0., 0.,  ..., nan, nan, 0.],
          [0., 0., 0.,  ..., nan, nan, nan],
          ...,
          [0., nan, 0.,  ..., 0., nan, 0.],
          [nan, 0., nan,  ..., 0., 0., 0.],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, 0., nan,  ..., nan, 0., nan],
          [nan, nan, nan,  ..., nan, 0., 0.],
          [nan, 0., 0.,  ..., nan, 0., 0.],
          ...,
          [nan, 0., 0.,  ..., nan, nan, 0.],
          [nan, nan, 0.,  ..., 0., nan, 0.],
          [0., nan, 0.,  ..., 0., 0., 0.]],

         [[nan, 0., 0.,  ..., 0., 0., nan],
          [0., 0., 0.,  ..., 0., nan, nan],
          [0., 0., 0.,  ..., nan, nan, nan],
          ...,
          [0., nan, 0.,  ..., 0., nan, nan],
          [0., nan, nan,  ..., nan, nan, nan],
          [0., nan, 0.,  ..., nan, 0., nan]]],


        [[[0., nan, nan,  ..., nan, 0., 0.],
          [nan, nan, nan,  ..., nan, nan, 0.],
          [0., 0., nan,  ..., nan, nan, nan],
          ...,
          [0., 0., 0.,  ..., nan, nan, nan],
          [nan, nan, 0.,  ..., 0., nan, nan],
          [0., nan, 0.,  ..., 0., 0., nan]],

         [[0., nan, 0.,  ..., nan, 0., 0.],
          [0., 0., nan,  ..., 0., 0., nan],
          [0., 0., nan,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., nan,  ..., nan, 0., 0.],
          [0., 0., nan,  ..., nan, 0., 0.]],

         [[nan, 0., 0.,  ..., 0., 0., nan],
          [nan, nan, 0.,  ..., 0., nan, nan],
          [nan, 0., 0.,  ..., nan, nan, nan],
          ...,
          [nan, 0., nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         ...,

         [[0., 0., 0.,  ..., 0., nan, 0.],
          [0., 0., 0.,  ..., nan, nan, 0.],
          [0., nan, 0.,  ..., 0., nan, 0.],
          ...,
          [0., 0., 0.,  ..., nan, nan, nan],
          [0., nan, 0.,  ..., nan, nan, 0.],
          [0., nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., 0., nan, 0.],
          [nan, 0., 0.,  ..., 0., 0., nan],
          ...,
          [nan, nan, 0.,  ..., 0., 0., 0.],
          [0., nan, 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., nan, 0.]],

         [[0., 0., 0.,  ..., 0., 0., nan],
          [0., nan, 0.,  ..., 0., 0., nan],
          [0., 0., nan,  ..., 0., 0., nan],
          ...,
          [0., nan, nan,  ..., 0., nan, nan],
          [0., nan, 0.,  ..., nan, nan, nan],
          [0., 0., nan,  ..., 0., 0., 0.]]]], device='cuda:0'),)
output:  (tensor([[[[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         ...,

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]]],


        [[[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         ...,

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0'),)
module:  Down(
  (maxpool_conv): Sequential(
    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (1): DoubleConv(
      (double_conv): Sequential(
        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU(inplace=True)
      )
    )
  )
)
input:  (tensor([[[[inf, nan, 0.,  ..., 0., nan, 0.],
          [0., 0., 0.,  ..., nan, 0., 0.],
          [0., nan, nan,  ..., nan, inf, 0.],
          ...,
          [0., inf, inf,  ..., 0., nan, 0.],
          [0., inf, 0.,  ..., 0., 0., 0.],
          [0., nan, inf,  ..., nan, 0., 0.]],

         [[0., 0., 0.,  ..., 0., inf, 0.],
          [nan, inf, 0.,  ..., nan, nan, inf],
          [nan, 0., 0.,  ..., nan, 0., 0.],
          ...,
          [nan, 0., inf,  ..., inf, inf, inf],
          [0., 0., inf,  ..., inf, nan, inf],
          [nan, inf, inf,  ..., inf, inf, inf]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [nan, 0., nan,  ..., 0., 0., 0.],
          [0., inf, 0.,  ..., 0., 0., 0.],
          ...,
          [inf, 0., 0.,  ..., 0., 0., nan],
          [0., 0., nan,  ..., 0., 0., 0.],
          [nan, 0., 0.,  ..., 0., 0., 0.]],

         ...,

         [[inf, 0., inf,  ..., 0., nan, 0.],
          [nan, inf, 0.,  ..., 0., 0., 0.],
          [nan, 0., 0.,  ..., 0., 0., 0.],
          ...,
          [inf, 0., nan,  ..., 0., 0., nan],
          [nan, 0., 0.,  ..., 0., 0., 0.],
          [inf, 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., nan,  ..., inf, 0., 0.],
          [inf, 0., inf,  ..., 0., 0., 0.],
          ...,
          [inf, inf, 0.,  ..., inf, 0., 0.],
          [nan, 0., inf,  ..., inf, nan, 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[inf, inf, 0.,  ..., inf, 0., inf],
          [nan, 0., 0.,  ..., inf, nan, inf],
          [inf, nan, 0.,  ..., inf, inf, 0.],
          ...,
          [nan, inf, 0.,  ..., inf, inf, inf],
          [nan, inf, inf,  ..., inf, inf, 0.],
          [inf, inf, nan,  ..., inf, inf, nan]]],


        [[[inf, 0., 0.,  ..., inf, 0., 0.],
          [0., nan, 0.,  ..., 0., 0., 0.],
          [0., nan, 0.,  ..., nan, nan, 0.],
          ...,
          [0., nan, inf,  ..., 0., inf, 0.],
          [0., nan, nan,  ..., nan, inf, 0.],
          [0., 0., 0.,  ..., inf, nan, inf]],

         [[inf, 0., 0.,  ..., 0., 0., inf],
          [nan, 0., nan,  ..., nan, nan, inf],
          [0., 0., 0.,  ..., 0., inf, 0.],
          ...,
          [0., 0., 0.,  ..., 0., inf, nan],
          [0., 0., inf,  ..., 0., inf, 0.],
          [nan, inf, inf,  ..., nan, nan, inf]],

         [[inf, 0., 0.,  ..., 0., 0., 0.],
          [inf, nan, nan,  ..., nan, nan, 0.],
          [inf, nan, inf,  ..., nan, nan, 0.],
          ...,
          [inf, 0., 0.,  ..., nan, nan, 0.],
          [0., 0., 0.,  ..., inf, nan, 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         ...,

         [[inf, 0., inf,  ..., inf, nan, 0.],
          [nan, 0., nan,  ..., nan, inf, 0.],
          [nan, 0., nan,  ..., 0., inf, 0.],
          ...,
          [inf, inf, 0.,  ..., inf, 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [nan, 0., inf,  ..., 0., nan, 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., nan, nan,  ..., nan, 0., 0.],
          [0., 0., 0.,  ..., 0., nan, inf],
          ...,
          [0., inf, 0.,  ..., inf, 0., 0.],
          [nan, 0., nan,  ..., inf, nan, 0.],
          [inf, 0., 0.,  ..., 0., 0., inf]],

         [[0., 0., 0.,  ..., inf, 0., 0.],
          [nan, 0., 0.,  ..., inf, nan, 0.],
          [inf, inf, nan,  ..., inf, nan, 0.],
          ...,
          [nan, inf, inf,  ..., 0., inf, inf],
          [nan, inf, nan,  ..., 0., inf, 0.],
          [inf, 0., inf,  ..., inf, nan, inf]]]], device='cuda:0'),)
output:  (tensor([[[[inf, nan, nan,  ..., inf, nan, inf],
          [inf, inf, inf,  ..., nan, inf, inf],
          [inf, nan, nan,  ..., nan, inf, inf],
          ...,
          [inf, inf, inf,  ..., inf, nan, inf],
          [inf, inf, inf,  ..., inf, nan, inf],
          [inf, nan, inf,  ..., nan, inf, inf]],

         [[inf, inf, nan,  ..., inf, inf, inf],
          [nan, inf, inf,  ..., nan, nan, inf],
          [nan, inf, inf,  ..., nan, inf, inf],
          ...,
          [nan, inf, inf,  ..., inf, inf, inf],
          [inf, inf, inf,  ..., inf, nan, inf],
          [nan, inf, inf,  ..., inf, inf, inf]],

         [[inf, inf, inf,  ..., inf, nan, inf],
          [nan, inf, nan,  ..., inf, inf, inf],
          [inf, inf, inf,  ..., inf, nan, inf],
          ...,
          [inf, inf, inf,  ..., inf, inf, nan],
          [inf, inf, nan,  ..., inf, nan, inf],
          [nan, inf, inf,  ..., inf, inf, inf]],

         ...,

         [[inf, inf, inf,  ..., inf, nan, inf],
          [nan, inf, inf,  ..., inf, inf, inf],
          [nan, inf, inf,  ..., inf, nan, inf],
          ...,
          [inf, inf, nan,  ..., inf, inf, nan],
          [nan, inf, nan,  ..., inf, nan, inf],
          [inf, inf, inf,  ..., inf, inf, inf]],

         [[nan, inf, inf,  ..., inf, nan, inf],
          [inf, inf, nan,  ..., inf, inf, inf],
          [inf, inf, inf,  ..., inf, nan, inf],
          ...,
          [inf, inf, inf,  ..., inf, inf, inf],
          [nan, inf, inf,  ..., inf, nan, inf],
          [inf, inf, inf,  ..., inf, inf, inf]],

         [[inf, inf, inf,  ..., inf, inf, inf],
          [nan, inf, inf,  ..., inf, nan, inf],
          [inf, nan, inf,  ..., inf, inf, inf],
          ...,
          [nan, inf, inf,  ..., inf, inf, inf],
          [nan, inf, inf,  ..., inf, inf, inf],
          [inf, inf, nan,  ..., inf, inf, nan]]],


        [[[inf, inf, nan,  ..., inf, nan, inf],
          [inf, nan, inf,  ..., inf, inf, inf],
          [inf, nan, inf,  ..., nan, nan, inf],
          ...,
          [inf, nan, inf,  ..., inf, inf, inf],
          [inf, nan, nan,  ..., nan, inf, inf],
          [inf, inf, inf,  ..., inf, nan, inf]],

         [[inf, inf, inf,  ..., inf, inf, inf],
          [nan, inf, nan,  ..., nan, nan, inf],
          [inf, inf, inf,  ..., inf, inf, inf],
          ...,
          [inf, inf, inf,  ..., inf, inf, nan],
          [inf, inf, inf,  ..., inf, inf, inf],
          [nan, inf, inf,  ..., nan, nan, inf]],

         [[inf, inf, inf,  ..., inf, inf, inf],
          [inf, nan, nan,  ..., nan, nan, inf],
          [inf, nan, inf,  ..., nan, nan, inf],
          ...,
          [inf, inf, inf,  ..., nan, nan, inf],
          [nan, inf, nan,  ..., inf, nan, inf],
          [inf, inf, inf,  ..., inf, inf, inf]],

         ...,

         [[inf, inf, inf,  ..., inf, nan, inf],
          [nan, inf, nan,  ..., nan, inf, inf],
          [nan, inf, nan,  ..., inf, inf, inf],
          ...,
          [inf, inf, inf,  ..., inf, inf, inf],
          [inf, inf, inf,  ..., inf, inf, inf],
          [nan, inf, inf,  ..., inf, nan, inf]],

         [[inf, inf, inf,  ..., inf, nan, inf],
          [inf, nan, nan,  ..., nan, inf, inf],
          [inf, inf, inf,  ..., inf, nan, inf],
          ...,
          [inf, inf, inf,  ..., inf, inf, inf],
          [nan, inf, nan,  ..., inf, nan, inf],
          [inf, inf, inf,  ..., inf, inf, inf]],

         [[inf, inf, inf,  ..., inf, inf, inf],
          [nan, inf, inf,  ..., inf, nan, inf],
          [inf, inf, nan,  ..., inf, nan, inf],
          ...,
          [nan, inf, inf,  ..., inf, inf, inf],
          [nan, inf, nan,  ..., inf, inf, inf],
          [inf, inf, inf,  ..., inf, nan, inf]]]], device='cuda:0'),)
module:  Down(
  (maxpool_conv): Sequential(
    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (1): DoubleConv(
      (double_conv): Sequential(
        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU(inplace=True)
      )
    )
  )
)
input:  (tensor([[[[nan, nan, nan,  ..., nan, nan, nan],
          [0., nan, nan,  ..., nan, nan, nan],
          [0., 0., nan,  ..., nan, nan, nan],
          ...,
          [0., nan, 0.,  ..., 0., nan, nan],
          [0., 0., nan,  ..., nan, nan, nan],
          [0., 0., nan,  ..., 0., nan, nan]],

         [[0., 0., 0.,  ..., 0., nan, 0.],
          [0., 0., nan,  ..., 0., 0., nan],
          [0., nan, nan,  ..., 0., nan, nan],
          ...,
          [0., nan, nan,  ..., nan, nan, nan],
          [0., nan, nan,  ..., nan, nan, nan],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., nan, 0.,  ..., 0., 0., 0.],
          [0., nan, nan,  ..., nan, 0., 0.],
          [0., nan, nan,  ..., 0., 0., 0.],
          ...,
          [0., nan, nan,  ..., 0., 0., 0.],
          [0., nan, nan,  ..., nan, 0., 0.],
          [0., nan, 0.,  ..., 0., 0., 0.]],

         ...,

         [[0., nan, 0.,  ..., 0., 0., 0.],
          [0., 0., nan,  ..., 0., 0., 0.],
          [nan, nan, nan,  ..., 0., nan, 0.],
          ...,
          [nan, nan, 0.,  ..., 0., 0., 0.],
          [0., nan, 0.,  ..., 0., nan, nan],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[nan, 0., nan,  ..., 0., nan, 0.],
          [0., nan, 0.,  ..., 0., nan, 0.],
          [0., 0., 0.,  ..., 0., nan, nan],
          ...,
          [nan, 0., nan,  ..., 0., 0., 0.],
          [nan, 0., 0.,  ..., 0., nan, 0.],
          [nan, 0., 0.,  ..., 0., 0., 0.]],

         [[nan, 0., nan,  ..., 0., nan, 0.],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, 0., nan,  ..., 0., 0., nan],
          ...,
          [nan, 0., 0.,  ..., nan, nan, nan],
          [nan, 0., 0.,  ..., nan, nan, nan],
          [0., 0., 0.,  ..., 0., 0., nan]]],


        [[[0., nan, nan,  ..., nan, 0., nan],
          [0., nan, nan,  ..., 0., 0., nan],
          [nan, nan, nan,  ..., nan, 0., 0.],
          ...,
          [0., 0., nan,  ..., nan, nan, 0.],
          [nan, 0., 0.,  ..., nan, 0., nan],
          [nan, nan, 0.,  ..., 0., nan, nan]],

         [[0., 0., nan,  ..., 0., nan, nan],
          [0., 0., nan,  ..., 0., 0., nan],
          [0., nan, nan,  ..., nan, 0., nan],
          ...,
          [nan, 0., 0.,  ..., nan, nan, nan],
          [0., nan, nan,  ..., nan, nan, nan],
          [0., nan, nan,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., nan, 0., 0.],
          [0., nan, nan,  ..., nan, nan, nan],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., nan, 0.,  ..., nan, nan, 0.],
          [0., nan, 0.,  ..., nan, 0., 0.],
          [0., 0., 0.,  ..., nan, nan, 0.]],

         ...,

         [[0., nan, 0.,  ..., 0., nan, 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [nan, nan, 0.,  ..., nan, nan, 0.],
          ...,
          [nan, nan, nan,  ..., nan, nan, 0.],
          [nan, nan, 0.,  ..., nan, nan, nan],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[nan, 0., 0.,  ..., 0., 0., nan],
          [0., nan, nan,  ..., 0., nan, 0.],
          [nan, 0., 0.,  ..., nan, 0., 0.],
          ...,
          [nan, nan, 0.,  ..., 0., 0., 0.],
          [nan, 0., 0.,  ..., 0., nan, 0.],
          [nan, nan, nan,  ..., nan, nan, 0.]],

         [[nan, 0., nan,  ..., nan, 0., nan],
          [0., 0., nan,  ..., 0., nan, nan],
          [nan, 0., 0.,  ..., nan, nan, nan],
          ...,
          [nan, 0., nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., 0., 0., nan],
          [0., 0., 0.,  ..., 0., 0., nan]]]], device='cuda:0'),)
output:  (tensor([[[[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         ...,

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]]],


        [[[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         ...,

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0'),)
module:  Down(
  (maxpool_conv): Sequential(
    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (1): DoubleConv(
      (double_conv): Sequential(
        (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): ReLU(inplace=True)
      )
    )
  )
)
input:  (tensor([[[[0., nan, 0.,  ..., nan, 0., 0.],
          [0., 0., 0.,  ..., 0., nan, nan],
          [0., 0., nan,  ..., nan, 0., nan],
          ...,
          [0., 0., nan,  ..., nan, 0., nan],
          [nan, 0., nan,  ..., nan, 0., nan],
          [0., 0., nan,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., nan, 0.,  ..., nan, 0., nan],
          [0., nan, 0.,  ..., 0., 0., nan],
          ...,
          [0., nan, 0.,  ..., nan, nan, nan],
          [0., 0., nan,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., nan]],

         [[nan, 0., nan,  ..., 0., nan, 0.],
          [0., nan, 0.,  ..., 0., 0., 0.],
          [0., 0., nan,  ..., 0., 0., 0.],
          ...,
          [nan, nan, nan,  ..., 0., nan, 0.],
          [nan, nan, nan,  ..., 0., 0., 0.],
          [nan, nan, 0.,  ..., 0., nan, 0.]],

         ...,

         [[0., 0., 0.,  ..., nan, 0., nan],
          [0., 0., nan,  ..., nan, nan, nan],
          [nan, 0., 0.,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., 0., nan, nan],
          [nan, nan, 0.,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[0., 0., 0.,  ..., nan, 0., nan],
          [0., nan, 0.,  ..., 0., 0., 0.],
          [nan, 0., 0.,  ..., nan, 0., nan],
          ...,
          [0., 0., nan,  ..., nan, nan, 0.],
          [0., 0., nan,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., nan]],

         [[0., nan, nan,  ..., 0., nan, nan],
          [0., 0., 0.,  ..., nan, 0., 0.],
          [0., 0., nan,  ..., 0., 0., nan],
          ...,
          [0., 0., nan,  ..., 0., 0., nan],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., nan, nan,  ..., nan, 0., 0.]]],


        [[[0., nan, nan,  ..., 0., 0., nan],
          [0., 0., nan,  ..., nan, 0., nan],
          [0., nan, 0.,  ..., nan, 0., nan],
          ...,
          [nan, 0., 0.,  ..., nan, 0., nan],
          [0., 0., nan,  ..., 0., 0., nan],
          [nan, nan, nan,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [nan, nan, nan,  ..., nan, 0., nan],
          [nan, 0., nan,  ..., nan, nan, 0.],
          ...,
          [0., 0., 0.,  ..., nan, 0., nan],
          [0., nan, 0.,  ..., 0., 0., 0.],
          [0., 0., nan,  ..., 0., 0., 0.]],

         [[nan, 0., 0.,  ..., nan, nan, nan],
          [0., 0., 0.,  ..., nan, nan, nan],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [nan, nan, nan,  ..., nan, 0., 0.],
          [nan, nan, nan,  ..., 0., nan, 0.],
          [nan, 0., nan,  ..., nan, nan, 0.]],

         ...,

         [[0., 0., 0.,  ..., 0., nan, nan],
          [nan, nan, 0.,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., 0., 0., nan],
          ...,
          [0., 0., nan,  ..., nan, nan, nan],
          [0., nan, 0.,  ..., nan, nan, nan],
          [0., nan, nan,  ..., nan, nan, nan]],

         [[0., 0., 0.,  ..., 0., 0., nan],
          [0., 0., 0.,  ..., nan, 0., nan],
          [0., 0., 0.,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., 0., 0., nan],
          [nan, nan, nan,  ..., nan, 0., nan],
          [nan, 0., 0.,  ..., 0., 0., nan]],

         [[0., 0., 0.,  ..., 0., nan, 0.],
          [0., 0., nan,  ..., 0., 0., nan],
          [0., 0., 0.,  ..., nan, nan, nan],
          ...,
          [0., 0., 0.,  ..., 0., 0., nan],
          [0., nan, nan,  ..., 0., 0., 0.],
          [nan, 0., 0.,  ..., 0., nan, nan]]]], device='cuda:0'),)
output:  (tensor([[[[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         ...,

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]]],


        [[[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         ...,

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]],

         [[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0'),)
module:  DoubleConv(
  (double_conv): Sequential(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
  )
)
input:  (tensor([[[[-1.0770e-06,         nan,         nan,  ..., -2.1554e-07,
           -5.6445e-07, -4.7836e-06],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -2.7411e-06,
                   nan, -3.6672e-06],
          [ 0.0000e+00,  0.0000e+00,  1.1022e-06,  ...,  8.6221e-06,
                   nan,  0.0000e+00],
          ...,
          [ 0.0000e+00,  3.9881e-06,         nan,  ...,  0.0000e+00,
                   nan, -4.1847e-06],
          [        nan,  0.0000e+00,         nan,  ...,         nan,
            1.0763e-06,         nan],
          [ 0.0000e+00,  0.0000e+00,  2.3919e-06,  ...,  0.0000e+00,
            0.0000e+00,  1.4145e-06]],

         [[ 1.9983e-06,         nan,         nan,  ...,  0.0000e+00,
                   nan,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
            0.0000e+00,  0.0000e+00],
          [        nan,  0.0000e+00, -1.8498e-06,  ...,  0.0000e+00,
            0.0000e+00,         nan],
          ...,
          [-1.4971e-06,  3.7837e-06, -1.1666e-06,  ...,         nan,
            0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00, -7.9626e-07,  ...,  0.0000e+00,
            0.0000e+00,         nan],
          [ 0.0000e+00,  0.0000e+00,  2.3208e-07,  ...,  0.0000e+00,
            0.0000e+00,  0.0000e+00]],

         [[ 4.7385e-06,  0.0000e+00,         nan,  ...,  0.0000e+00,
            0.0000e+00,  0.0000e+00],
          [        nan,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
            0.0000e+00,  0.0000e+00],
          [-4.1108e-06,         nan, -4.9234e-06,  ...,  0.0000e+00,
            0.0000e+00,         nan],
          ...,
          [        nan,  3.0835e-07,  3.9610e-06,  ...,  0.0000e+00,
            0.0000e+00,  0.0000e+00],
          [-7.1813e-07,         nan,  0.0000e+00,  ...,  0.0000e+00,
            0.0000e+00,  0.0000e+00],
          [ 2.6881e-06, -2.2136e-06,  1.4533e-06,  ...,         nan,
            0.0000e+00,  0.0000e+00]],

         ...,

         [[ 0.0000e+00,         nan,  0.0000e+00,  ...,  9.7642e-07,
            0.0000e+00,         nan],
          [ 0.0000e+00, -5.3315e-06,  0.0000e+00,  ...,  1.2401e-06,
            0.0000e+00,  1.1116e-06],
          [ 0.0000e+00, -3.3988e-06, -7.5644e-06,  ...,         nan,
            0.0000e+00, -3.1273e-06],
          ...,
          [ 0.0000e+00, -5.9788e-06,  0.0000e+00,  ...,         nan,
            0.0000e+00, -2.3039e-06],
          [        nan,  7.8545e-06,  0.0000e+00,  ...,  0.0000e+00,
                   nan, -6.7790e-06],
          [ 1.4957e-06,  0.0000e+00,         nan,  ...,  0.0000e+00,
           -3.4793e-07, -3.4952e-06]],

         [[-4.3566e-07, -2.4106e-06,         nan,  ...,  0.0000e+00,
            0.0000e+00,  2.6585e-06],
          [ 1.4497e-06,         nan, -3.7624e-07,  ...,  0.0000e+00,
            0.0000e+00,         nan],
          [ 0.0000e+00,  0.0000e+00, -1.0612e-06,  ...,  0.0000e+00,
            0.0000e+00,         nan],
          ...,
          [ 0.0000e+00, -7.1858e-06,  0.0000e+00,  ...,         nan,
            0.0000e+00,  4.5929e-06],
          [ 0.0000e+00,  1.9534e-06,  0.0000e+00,  ...,         nan,
            3.5160e-07,         nan],
          [ 0.0000e+00,         nan,  0.0000e+00,  ...,  0.0000e+00,
            0.0000e+00,  1.2576e-06]],

         [[        nan,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
                   nan,  1.8615e-06],
          [ 0.0000e+00,  0.0000e+00, -3.9959e-06,  ...,  0.0000e+00,
            0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  4.5045e-06,         nan,  ...,  0.0000e+00,
            0.0000e+00,  0.0000e+00],
          ...,
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
                   nan,  0.0000e+00],
          [ 1.8773e-06,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
            5.1071e-06,  0.0000e+00],
          [        nan,  0.0000e+00, -2.8440e-06,  ...,  1.5843e-06,
                   nan,  8.1195e-07]]],


        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
           -8.4354e-07, -1.4959e-06],
          [ 0.0000e+00,         nan,  0.0000e+00,  ...,  0.0000e+00,
                   nan,  0.0000e+00],
          [-4.3265e-06,         nan,  4.5370e-06,  ...,  2.0134e-06,
            0.0000e+00,  3.4693e-06],
          ...,
          [ 0.0000e+00, -7.8086e-06,         nan,  ...,         nan,
            0.0000e+00,         nan],
          [ 0.0000e+00,         nan,         nan,  ...,  0.0000e+00,
           -4.2090e-06,         nan],
          [ 0.0000e+00,  5.9591e-06, -8.9497e-06,  ...,  0.0000e+00,
            0.0000e+00,  0.0000e+00]],

         [[ 0.0000e+00,  0.0000e+00, -6.9064e-07,  ..., -4.2166e-06,
            0.0000e+00,  8.1588e-07],
          [ 6.3878e-07,         nan,  4.9560e-06,  ...,         nan,
                   nan, -3.5320e-07],
          [-4.1459e-06,         nan, -4.5396e-06,  ...,  7.6643e-06,
                   nan,  1.9594e-06],
          ...,
          [ 0.0000e+00,  0.0000e+00,         nan,  ...,  0.0000e+00,
            0.0000e+00,  1.0016e-05],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
            0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,         nan,  ...,  1.5549e-06,
            0.0000e+00,  0.0000e+00]],

         [[ 0.0000e+00,  0.0000e+00,  3.5679e-06,  ...,  1.0477e-06,
            0.0000e+00,  0.0000e+00],
          [        nan, -2.1425e-06,         nan,  ..., -8.1391e-07,
                   nan,  1.8545e-06],
          [ 2.8034e-06,  5.5354e-06,  0.0000e+00,  ...,  0.0000e+00,
                   nan,  3.4234e-06],
          ...,
          [ 3.3275e-06, -1.9510e-06, -7.8801e-06,  ...,  0.0000e+00,
                   nan,  0.0000e+00],
          [ 1.7260e-06,         nan,         nan,  ...,  0.0000e+00,
            0.0000e+00,  0.0000e+00],
          [ 9.2036e-07,  5.3097e-06,  3.2398e-07,  ...,         nan,
            0.0000e+00,  0.0000e+00]],

         ...,

         [[ 0.0000e+00, -1.0452e-06,         nan,  ...,  0.0000e+00,
            0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,         nan,  0.0000e+00,  ...,         nan,
           -4.7006e-07,         nan],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,         nan,
            1.7018e-06, -8.6187e-06],
          ...,
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,         nan,
            0.0000e+00, -5.7199e-06],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.3974e-07,
            7.9359e-07,  3.4111e-06],
          [ 0.0000e+00,         nan,  0.0000e+00,  ...,  0.0000e+00,
                   nan,  0.0000e+00]],

         [[ 0.0000e+00,  0.0000e+00, -5.5772e-06,  ...,  1.8044e-06,
           -2.0293e-06,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  4.0691e-06,  ..., -5.8176e-06,
            0.0000e+00,         nan],
          [ 4.1863e-06,  0.0000e+00,         nan,  ...,         nan,
            7.9990e-06,  3.2043e-06],
          ...,
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
            0.0000e+00,  3.1910e-06],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,         nan,
            3.4752e-06,         nan],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  1.8285e-06,
            0.0000e+00,  0.0000e+00]],

         [[ 3.0657e-06,         nan,         nan,  ...,         nan,
            1.7659e-06,  2.5552e-07],
          [ 0.0000e+00, -4.4277e-07,  1.3040e-05,  ..., -2.3727e-06,
            2.4712e-06,         nan],
          [ 0.0000e+00,  0.0000e+00,  3.3717e-06,  ...,  0.0000e+00,
            3.3232e-06,         nan],
          ...,
          [ 0.0000e+00,         nan,  6.0876e-06,  ...,  2.5952e-06,
            0.0000e+00,  0.0000e+00],
          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  6.7145e-06,
           -3.1330e-06,  0.0000e+00],
          [ 0.0000e+00,         nan,         nan,  ...,  0.0000e+00,
                   nan,  2.7686e-06]]]], device='cuda:0'),)
output:  (tensor([[[[-1.0770e-06,         nan,         nan,  ..., -2.1554e-07,
           -5.6445e-07, -4.7836e-06],
          [ 1.5795e-06,  7.8614e-08,  1.4825e-06,  ..., -2.7411e-06,
                   nan, -3.6672e-06],
          [-3.9914e-06, -5.4344e-06,  1.1022e-06,  ...,  8.6221e-06,
                   nan, -3.0997e-06],
          ...,
          [-9.0761e-07,  3.9881e-06,         nan,  ..., -1.1450e-06,
                   nan, -4.1847e-06],
          [        nan, -1.0689e-06,         nan,  ...,         nan,
            1.0763e-06,         nan],
          [ 2.1822e-06, -2.8445e-06,  2.3919e-06,  ..., -1.2137e-06,
           -9.0139e-07,  1.4145e-06]],

         [[ 1.9983e-06,         nan,         nan,  ...,  3.4066e-07,
                   nan,  1.8231e-06],
          [ 1.8916e-06,  9.0628e-07, -4.0998e-06,  ...,  4.0028e-06,
            5.5204e-07, -6.6070e-07],
          [        nan, -3.5869e-06, -1.8498e-06,  ...,  2.8574e-06,
           -2.9456e-06,         nan],
          ...,
          [-1.4971e-06,  3.7837e-06, -1.1666e-06,  ...,         nan,
            1.2627e-06, -7.4506e-06],
          [        nan, -1.1943e-06, -7.9626e-07,  ..., -4.0981e-06,
           -7.5966e-08,         nan],
          [ 5.7229e-07, -2.5344e-06,  2.3208e-07,  ...,  3.3542e-06,
            1.6263e-06,  4.8398e-06]],

         [[ 4.7385e-06,  5.6942e-06,         nan,  ...,  4.6418e-06,
                   nan, -7.4259e-07],
          [        nan, -6.8511e-07, -1.9860e-06,  ...,  5.1329e-06,
           -1.2810e-06, -1.8994e-06],
          [-4.1108e-06,         nan, -4.9234e-06,  ...,  2.4055e-06,
           -1.1523e-06,         nan],
          ...,
          [        nan,  3.0835e-07,  3.9610e-06,  ..., -3.0156e-06,
            1.5769e-06,  3.7752e-06],
          [-7.1813e-07,         nan, -2.4485e-06,  ..., -8.7182e-07,
                   nan, -2.4413e-06],
          [ 2.6881e-06, -2.2136e-06,  1.4533e-06,  ...,         nan,
            3.8670e-06,  1.8962e-07]],

         ...,

         [[ 2.6581e-06,         nan,         nan,  ...,  9.7642e-07,
           -5.4583e-06,         nan],
          [-6.5128e-07, -5.3315e-06,  2.0559e-06,  ...,  1.2401e-06,
            2.4724e-06,  1.1116e-06],
          [ 1.4573e-07, -3.3988e-06, -7.5644e-06,  ...,         nan,
           -2.3264e-06, -3.1273e-06],
          ...,
          [-3.3424e-07, -5.9788e-06, -3.7661e-07,  ...,         nan,
           -8.2422e-06, -2.3039e-06],
          [        nan,  7.8545e-06,  2.9888e-06,  ...,  1.2023e-07,
                   nan, -6.7790e-06],
          [ 1.4957e-06,  4.9390e-07,         nan,  ..., -4.7204e-06,
           -3.4793e-07, -3.4952e-06]],

         [[-4.3566e-07, -2.4106e-06,         nan,  ...,  6.2469e-08,
           -1.1603e-06,  2.6585e-06],
          [ 1.4497e-06,         nan, -3.7624e-07,  ..., -1.6879e-06,
           -1.5934e-05,         nan],
          [ 9.0441e-07, -9.0890e-07, -1.0612e-06,  ...,  2.8720e-06,
           -1.8424e-06,         nan],
          ...,
          [ 1.0591e-06, -7.1858e-06,  1.0401e-06,  ...,         nan,
           -7.3143e-06,  4.5929e-06],
          [ 5.6999e-07,  1.9534e-06, -2.9210e-06,  ...,         nan,
            3.5160e-07,         nan],
          [ 2.5048e-06,         nan,  2.7904e-06,  ..., -3.0879e-06,
            3.4066e-07,  1.2576e-06]],

         [[        nan, -7.2293e-07, -6.1847e-07,  ..., -3.8116e-06,
                   nan,  1.8615e-06],
          [ 5.1040e-07, -2.4373e-06, -3.9959e-06,  ...,  7.1221e-06,
            7.3281e-06, -4.7531e-06],
          [ 2.2216e-06,  4.5045e-06,         nan,  ...,  9.7207e-07,
           -2.6971e-06, -3.1421e-06],
          ...,
          [-3.6742e-06, -1.1340e-06, -2.2103e-06,  ...,  3.8970e-06,
                   nan, -3.2983e-06],
          [ 1.8773e-06,  6.3970e-06, -1.7193e-06,  ...,  4.1556e-06,
            5.1071e-06,  2.0863e-06],
          [        nan,  7.3889e-07, -2.8440e-06,  ...,  1.5843e-06,
                   nan,  8.1195e-07]]],


        [[[-1.8127e-06, -4.7992e-07,         nan,  ...,  3.0227e-06,
           -8.4354e-07, -1.4959e-06],
          [-1.2755e-07,         nan,  9.6922e-06,  ...,  2.9462e-06,
                   nan, -4.0111e-07],
          [-4.3265e-06,         nan,  4.5370e-06,  ...,  2.0134e-06,
            2.3901e-07,  3.4693e-06],
          ...,
          [ 1.2853e-06, -7.8086e-06,         nan,  ...,         nan,
            1.6160e-07,         nan],
          [-4.2576e-06,         nan,         nan,  ...,  1.0910e-05,
           -4.2090e-06,         nan],
          [ 1.2988e-06,  5.9591e-06, -8.9497e-06,  ...,  5.6672e-06,
           -2.9101e-06, -4.0811e-06]],

         [[ 1.0497e-06,  1.7298e-06, -6.9064e-07,  ..., -4.2166e-06,
           -3.8586e-06,  8.1588e-07],
          [ 6.3878e-07,         nan,  4.9560e-06,  ...,         nan,
                   nan, -3.5320e-07],
          [-4.1459e-06,         nan, -4.5396e-06,  ...,  7.6643e-06,
                   nan,  1.9594e-06],
          ...,
          [ 2.1965e-06,  3.6498e-06,         nan,  ...,  1.4173e-07,
            3.4876e-07,  1.0016e-05],
          [        nan, -6.8085e-07,  1.0712e-05,  ..., -7.7547e-06,
                   nan, -3.9209e-07],
          [-3.1550e-06, -1.9974e-07,         nan,  ...,  1.5549e-06,
           -2.2917e-06,  1.7513e-06]],

         [[ 1.9149e-06,  2.3805e-07,  3.5679e-06,  ...,  1.0477e-06,
           -4.9869e-06,  6.1927e-06],
          [        nan, -2.1425e-06,         nan,  ..., -8.1391e-07,
                   nan,  1.8545e-06],
          [ 2.8034e-06,  5.5354e-06, -1.0567e-06,  ..., -4.0991e-06,
                   nan,  3.4234e-06],
          ...,
          [ 3.3275e-06, -1.9510e-06, -7.8801e-06,  ...,  2.1399e-06,
                   nan, -8.5710e-06],
          [ 1.7260e-06,         nan,         nan,  ..., -2.1891e-06,
                   nan,  1.6398e-06],
          [ 9.2036e-07,  5.3097e-06,  3.2398e-07,  ...,         nan,
           -1.0965e-06, -3.4247e-06]],

         ...,

         [[-3.5911e-06, -1.0452e-06,         nan,  ...,  3.6114e-06,
           -3.4522e-06, -7.6850e-06],
          [ 1.0192e-06,         nan,  6.7787e-06,  ...,         nan,
           -4.7006e-07,         nan],
          [        nan, -7.2604e-07,  1.3649e-07,  ...,         nan,
            1.7018e-06, -8.6187e-06],
          ...,
          [-2.0463e-06,  2.4925e-07,  3.1265e-06,  ...,         nan,
            9.3596e-06, -5.7199e-06],
          [ 3.3216e-06, -8.4961e-07,  6.7594e-06,  ..., -1.3974e-07,
            7.9359e-07,  3.4111e-06],
          [ 1.8027e-06,         nan,  2.2296e-06,  ..., -6.0855e-07,
                   nan, -2.6163e-06]],

         [[        nan, -3.5766e-06, -5.5772e-06,  ...,  1.8044e-06,
           -2.0293e-06,  6.4848e-07],
          [-2.9061e-06,  7.3608e-06,  4.0691e-06,  ..., -5.8176e-06,
            9.2488e-06,         nan],
          [ 4.1863e-06,  1.4489e-06,         nan,  ...,         nan,
            7.9990e-06,  3.2043e-06],
          ...,
          [ 7.8014e-06,  2.5695e-06, -5.9828e-06,  ...,  1.2696e-06,
            6.4439e-06,  3.1910e-06],
          [        nan,  3.7325e-06, -2.0308e-06,  ...,         nan,
            3.4752e-06,         nan],
          [-2.0381e-06,  2.6462e-06,  7.1107e-07,  ...,  1.8285e-06,
            3.9970e-07,  1.5064e-06]],

         [[ 3.0657e-06,         nan,         nan,  ...,         nan,
            1.7659e-06,  2.5552e-07],
          [-4.7983e-06, -4.4277e-07,  1.3040e-05,  ..., -2.3727e-06,
            2.4712e-06,         nan],
          [        nan, -3.6627e-06,  3.3717e-06,  ...,  1.3715e-06,
            3.3232e-06,         nan],
          ...,
          [-7.7642e-07,         nan,  6.0876e-06,  ...,  2.5952e-06,
           -5.8587e-06,  1.4281e-06],
          [-3.4469e-06,  6.0382e-06,  6.3899e-06,  ...,  6.7145e-06,
           -3.1330e-06, -2.7961e-06],
          [ 1.3450e-06,         nan,         nan,  ...,  3.3761e-06,
                   nan,  2.7686e-06]]]], device='cuda:0'),)
